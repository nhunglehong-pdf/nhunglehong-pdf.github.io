---
layout: lectures_and_projects
year: 2018
title: Lectures and Projects
lectures:
  - title: Đại số tuyến tính
    href: "/pdf/2018/lectures-and-projects/linearalgebra.pdf"
    authors: ['linh', 'nghia', 'trung']
  - title: Tối ưu hóa
    href: "/pdf/2018/lectures-and-projects/optimization.pdf"
    authors: ['nhat']
  - title: Giải tích
    href: "/pdf/2018/lectures-and-projects/calculus.pdf"
    authors: ['trong', 'linh']
  - title: Xác suất và phân phối
    href: "/pdf/2018/lectures-and-projects/probability_distribution.pdf"
    authors: ['theanh', 'linh', 'manh']
projects:
  - title: Neural Network
    href: "/pdf/2018/lectures-and-projects/neural-network-project-pima-2018.pdf"
    desc: Năm 1958, Frank Rosenblatt mô tả thuật toán perceptron, tiền thân của neural network. Trải qua hơn nửa thế kỉ phát triển, với biết bao thăng trầm, hiện nay neural network là một trong những mô hình phổ biến nhất của trí tuệ nhân tạo và máy học, cơ sở của các thành tựu trong học sâu (deep learning). Ở dự án này, các bạn sẽ sử dụng các kiến thức toán đã được học để nghiên cứu về mạng nơron có nhiều lớp (multilayer perceptron).
  - title: Support Vector Machine
    desc: Support Vector Machines (SVMs) là những mô hình học có giám sát được phát minh bởi Vladimir Naumovich Vapnik và Alexey Yakovlevich Chervonenkis năm 1963. Mô hình này được dùng rất nhiều trong bài toán phân lớp dữ liệu (được áp dụng trong cả bài toán phân loại lẫn hồi quy). Ở phiên bản gốc, SVMs là một mô hình nhị phân gồm một hệ điểm dữ liệu (được gắn nhãn 1 hoặc −1) biểu diễn trên một không gian nhiều chiều, SVMs hỗ trợ xây dựng một siêu phẳng để phân hệ dữ liệu trên thành hai lớp (mỗi lớp tương ứng với một nhãn). Không chỉ dừng lại ở bài toán phân lớp, SVMs yêu cầu các điểm dữ liệu nằm càng xa siêu phẳng càng tốt.
    href: "/pdf/2018/lectures-and-projects/svm-project-pima-2018.pdf"
  - title: Principal Component Analysis
    desc: Principal Component Analysis (PCA) là một trong những kỹ thuật làm giảm số chiều (dimension reduction) của không gian dữ liệu đang xét, rất thông dụng trong thống kê (statistics), học máy (machine learning), hay lý thuyết thông tin (information theory). Công cụ chính để xây dựng phương pháp này là ma trận và cơ sở tương ứng với vector riêng trong Đại số Tuyến tính. Ý tưởng chính là biểu diễn lại các vector dữ liệu trong một cơ sở con thích hợp (cơ sở ứng với các giá trị riêng lớn nhất) để chỉ cần lưu lại những thông tin trọng yếu của toàn bộ dữ liệu. Trong dự án này, các bạn sẽ tìm hiểu nền tảng lý thuyết của PCA và áp dụng công cụ này vào một dữ liệu cụ thể.
    href: "/pdf/2018/lectures-and-projects/pca-project-pima-2018.pdf"
  - title: Naive Bayes
    desc: Được nghiên cứu rộng rãi từ thập niên 50, Naive Bayes là một phương pháp phân loại bắt nguồn từ lí thuyết Bayes và điều giả sử rằng các sự kiện trong điểm dữ liệu đều phân biệt. Phương pháp này nổi tiếng về việc có mô hình đơn giản và tương đối hiệu quả với những vấn đề mà ta không có quá nhiều dữ liệu. Trong trại hè PIMA, các bạn sẽ được học về Naive Bayes và cách áp dụng phương pháp này cho mục đích phân loại.
    href: "/pdf/2018/lectures-and-projects/naive-bayes-project-pima-2018.pdf"
---

